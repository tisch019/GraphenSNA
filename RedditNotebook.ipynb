{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tisch019/GraphenSNA/blob/main/RedditNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpDn1zJVj6Yh"
      },
      "source": [
        "Kpierter und angepaster Text aus dem Tutorial : https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests"
      ],
      "metadata": {
        "id": "sKf7WPPgmwKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXIgLBnkj6Yq",
        "outputId": "75856cf2-9993-401d-db39-117b6016a5ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "CLIENT_ID = 'imWZo6dEVJi6DQFj-GvUkQ'\n",
        "SECRET_TOKEN = 'e6jNSjxu6qLD0MdUKzkwZZuxeQR_fA'\n",
        "\n",
        "USERNAME = 'poliphemis'\n",
        "PASSWORD = 'fg789Hzu4'\n",
        "\n",
        "# note that CLIENT_ID refers to 'personal use script' and SECRET_TOKEN to 'token'\n",
        "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_TOKEN)\n",
        "\n",
        "# here we pass our login method (password), username, and password\n",
        "data = {'grant_type': 'password',\n",
        "        'username': USERNAME,\n",
        "        'password': PASSWORD}\n",
        "\n",
        "# setup our header info, which gives reddit a brief description of our app\n",
        "headers = {'User-Agent': 'Hochschulprojekt zur Graphen SNA'}\n",
        "\n",
        "# send our request for an OAuth token\n",
        "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
        "                    auth=auth, data=data, headers=headers)\n",
        "\n",
        "# convert response to JSON and pull access_token value\n",
        "TOKEN = res.json()['access_token']\n",
        "\n",
        "# add authorization to our headers dictionary\n",
        "headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
        "\n",
        "# while the token is valid (~2 hours) we just add headers=headers to our requests\n",
        "requests.get('https://oauth.reddit.com/api/v1/me', headers=headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS54NhuBj6Yw"
      },
      "outputs": [],
      "source": [
        "# Array of choosen reddits\n",
        "reddits = [\"python\", \"java\", \"php\"]\n",
        "\n",
        "# Dictionary of API-responses\n",
        "responses = {}\n",
        "# get hot posts of choosen reddits\n",
        "for reddit in reddits:\n",
        "  responses[reddit] = requests.get(\"https://oauth.reddit.com/r/\"+reddit+\"/hot\",\n",
        "                   headers=headers, params={'limit':'20', 't':'month'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UafAc4_hj6Yy"
      },
      "outputs": [],
      "source": [
        "# initialize dictionary of dataframes\n",
        "dataframes = {}\n",
        "# add all responses to dictionary\n",
        "for reddit in reddits:\n",
        "  dataframes[reddit] = pd.DataFrame()  # initialize dataframe\n",
        "  # loop through each post retrieved from GET request\n",
        "  for post in responses[reddit].json()['data']['children']:\n",
        "      # append relevant data to dataframe\n",
        "      dataframes[reddit] = dataframes[reddit].append({\n",
        "          'subreddit': post['data']['subreddit'],\n",
        "          'author': post['data']['author'],\n",
        "          'title': post['data']['title'],\n",
        "          'selftext': post['data']['selftext'],\n",
        "          'upvote_ratio': post['data']['upvote_ratio'],\n",
        "          'ups': post['data']['ups'],\n",
        "          'downs': post['data']['downs'],\n",
        "          'score': post['data']['score']\n",
        "      }, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLqCpzp2j6Yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ec87be-ca22-4c9a-8df0-dfdc0d1b586d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 author  downs  ...    ups upvote_ratio\n",
            "0            Im__Joseph    0.0  ...   12.0         0.94\n",
            "1            Im__Joseph    0.0  ...    0.0         0.43\n",
            "2        n3buchadnezzar    0.0  ...   49.0         0.86\n",
            "3         Quantumlyhigh    0.0  ...   63.0         0.89\n",
            "4             vapen_hem    0.0  ...  308.0         0.90\n",
            "5            Fanrounder    0.0  ...   33.0         0.76\n",
            "6            SudoLogeek    0.0  ...    6.0         0.88\n",
            "7              hobbesid    0.0  ...    4.0         0.71\n",
            "8       These-Ease-4410    0.0  ...    6.0         0.80\n",
            "9          ellsphillips    0.0  ...    5.0         0.86\n",
            "10             EmmaGao8    0.0  ...    8.0         0.75\n",
            "11  ConstructionHot6883    0.0  ...    1.0         1.00\n",
            "12        LinkusThinkus    0.0  ...   98.0         0.92\n",
            "13       sepandhaghighi    0.0  ...   47.0         0.92\n",
            "14            rszamszur    0.0  ...   20.0         0.82\n",
            "15            AfroBoyUg    0.0  ...    1.0         0.57\n",
            "16            Feitgemel    0.0  ...    3.0         0.72\n",
            "17         sethmlarson_    0.0  ...   38.0         0.86\n",
            "18   SwitchArtistic2709    0.0  ...    1.0         0.67\n",
            "19          Plane_Smell    0.0  ...    0.0         0.33\n",
            "20         felix-hilden    0.0  ...    1.0         0.67\n",
            "21             pabari56    0.0  ...   16.0         0.85\n",
            "\n",
            "[22 rows x 8 columns]\n",
            "                author  downs  ...    ups upvote_ratio\n",
            "0              desrtfx    0.0  ...  323.0         0.84\n",
            "1              desrtfx    0.0  ...  237.0         0.95\n",
            "2            lukaseder    0.0  ...   29.0         0.95\n",
            "3      lessthanoptimal    0.0  ...   22.0         0.96\n",
            "4             galovics    0.0  ...    6.0         0.88\n",
            "5             daviddel    0.0  ...   64.0         0.96\n",
            "6               jrh206    0.0  ...    0.0         0.50\n",
            "7   CraigMcDonaldCodes    0.0  ...    1.0         1.00\n",
            "8        gunnarmorling    0.0  ...    1.0         1.00\n",
            "9               henk53    0.0  ...   17.0         0.78\n",
            "10       santanu_sinha    0.0  ...   41.0         0.93\n",
            "11               rmoff    0.0  ...   55.0         0.85\n",
            "12          pantsbuild    0.0  ...   15.0         0.75\n",
            "13        sunshowerjoe    0.0  ...   28.0         0.92\n",
            "14      MaterialFerret    0.0  ...    8.0         0.79\n",
            "15         BlueGoliath    0.0  ...   71.0         0.92\n",
            "16             Clivern    0.0  ...   35.0         0.87\n",
            "17           mike_jack    0.0  ...   53.0         0.87\n",
            "18             VM_Unix    0.0  ...    2.0         0.57\n",
            "19     neverendingcopy    0.0  ...    4.0         1.00\n",
            "20              bomomu    0.0  ...  133.0         0.97\n",
            "21             MrMforM    0.0  ...    7.0         0.65\n",
            "\n",
            "[22 rows x 8 columns]\n",
            "                  author  downs  ...   ups upvote_ratio\n",
            "0              brendt_gd    0.0  ...   6.0         0.80\n",
            "1              FrenkyNet    0.0  ...  33.0         0.94\n",
            "2                 tigitz    0.0  ...  90.0         0.96\n",
            "3               jmp_ones    0.0  ...   0.0         0.45\n",
            "4                quenjay    0.0  ...  11.0         0.74\n",
            "5          IvanVoitovych    0.0  ...   4.0         0.61\n",
            "6          TimothePearce    0.0  ...   0.0         0.48\n",
            "7           ankitpokhrel    0.0  ...  61.0         0.93\n",
            "8              brendt_gd    0.0  ...  49.0         0.90\n",
            "9           JordanLeDoux    0.0  ...   4.0         1.00\n",
            "10              JR2media    0.0  ...  17.0         0.79\n",
            "11   okredditiguessitsme    0.0  ...   3.0         0.54\n",
            "12  Comfortable-Will-270    0.0  ...   0.0         0.48\n",
            "13             wcarabain    0.0  ...  17.0         0.70\n",
            "14         IvanVoitovych    0.0  ...  27.0         0.80\n",
            "15         adityaoberai1    0.0  ...  35.0         0.74\n",
            "16              sinnerou    0.0  ...  50.0         0.82\n",
            "17        fercircularbuf    0.0  ...  62.0         0.90\n",
            "18            leoleoloso    0.0  ...  13.0         0.81\n",
            "19           dradzenglor    0.0  ...   1.0         0.54\n",
            "20              agaroud9    0.0  ...  24.0         0.83\n",
            "\n",
            "[21 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "for reddit in reddits:\n",
        "  print(dataframes[reddit])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAv09XkKj6Y1",
        "outputId": "b4a4b758-0595-4a0b-9443-73257faef97b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['approved_at_utc', 'subreddit', 'selftext', 'author_fullname', 'saved', 'mod_reason_title', 'gilded', 'clicked', 'title', 'link_flair_richtext', 'subreddit_name_prefixed', 'hidden', 'pwls', 'link_flair_css_class', 'downs', 'top_awarded_type', 'hide_score', 'name', 'quarantine', 'link_flair_text_color', 'upvote_ratio', 'author_flair_background_color', 'subreddit_type', 'ups', 'total_awards_received', 'media_embed', 'author_flair_template_id', 'is_original_content', 'user_reports', 'secure_media', 'is_reddit_media_domain', 'is_meta', 'category', 'secure_media_embed', 'link_flair_text', 'can_mod_post', 'score', 'approved_by', 'is_created_from_ads_ui', 'author_premium', 'thumbnail', 'edited', 'author_flair_css_class', 'author_flair_richtext', 'gildings', 'content_categories', 'is_self', 'mod_note', 'created', 'link_flair_type', 'wls', 'removed_by_category', 'banned_by', 'author_flair_type', 'domain', 'allow_live_comments', 'selftext_html', 'likes', 'suggested_sort', 'banned_at_utc', 'view_count', 'archived', 'no_follow', 'is_crosspostable', 'pinned', 'over_18', 'all_awardings', 'awarders', 'media_only', 'can_gild', 'spoiler', 'locked', 'author_flair_text', 'treatment_tags', 'visited', 'removed_by', 'num_reports', 'distinguished', 'subreddit_id', 'author_is_blocked', 'mod_reason_by', 'removal_reason', 'link_flair_background_color', 'id', 'is_robot_indexable', 'report_reasons', 'author', 'discussion_type', 'num_comments', 'send_replies', 'whitelist_status', 'contest_mode', 'mod_reports', 'author_patreon_flair', 'author_flair_text_color', 'permalink', 'parent_whitelist_status', 'stickied', 'url', 'subreddit_subscribers', 'created_utc', 'num_crossposts', 'media', 'is_video'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Alle Keywörter die bei einem Post abgefragt werden können\n",
        "\n",
        "post['data'].keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCT_i51sj6Y-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "23ab10d1-14d7-41a8-b451-ae1d7676835f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-b848f38329ed>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#reorganising the data as a dictionary with authors (=future nodes in network) as keys\n",
        "author_dict = {}\n",
        "\n",
        "#HIER IN DER REGEL AUSKOMMENTIEREN\n",
        "number_of_nodes = len(reddits)\n",
        "\n",
        "#TODO ups beziehen sich bei mehreren Posts bislang nur auf den ersten Post in der Schleife!\n",
        "for key in dataframes:\n",
        "    if dataframes[key]['author'] in author_dict:\n",
        "      author_dict[dataframes[key]['author']['subreddit'].append(row.get('subreddit'))\n",
        "    else:\n",
        "        number_of_nodes += 1\n",
        "        author_dict[row.get('Autor')] = {\n",
        "         'author_fullname': row.get('Autor_fullname'),\n",
        "         'subreddit': [row.get('subreddit')],\n",
        "         'ups': row.get('ups'),\n",
        "         'node_id': number_of_nodes\n",
        "        }\n",
        "\n",
        "author_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_vertex_in_pajek(count_vertices, name, shape, color):\n",
        "  return '\\n {} \"{}\" {} ic {} bc {}'.format(count_vertices, name, shape, color, color)\n",
        "\n",
        "def make_arc_in_pajek(from_vertex, to_vertex, weight=1):\n",
        "  return ' {} {} {}\\n'.format(from_vertex, to_vertex, weight)\n",
        "\n",
        "pajek_vertices = \"*Vertices {}\".format(len(reddits)+len(author_dict.keys()))\n",
        "pajek_arcs = '*Arcs :1 \"Authors in subreddits\"\\n'\n",
        "\n",
        "counter = 1\n",
        "#make vertices for subreddits\n",
        "for subreddit in reddits:\n",
        "  pajek_vertices = pajek_vertices + make_vertex_in_pajek(counter, subreddit, 'box', 'Cornflowerblue')\n",
        "  counter += 1\n",
        "\n",
        "#make vertices for authors and add arcs\n",
        "for author in author_dict:\n",
        "  pajek_vertices = pajek_vertices + make_vertex_in_pajek(author_dict[author]['node_id'], author, 'ellipse', 'Melon')\n",
        "\n",
        "#add one arc for each subreddit the author has a top post in\n",
        "i = 1\n",
        "\n",
        "#PLEASE ADAPT THESE LINES IF THE reddits-ARRAY IS NOT CORRECTLY USED!!!\n",
        "for subreddit in reddits:\n",
        "  num = author_dict[author]['subreddit'].count(subreddit)\n",
        "  if num > 0:\n",
        "    pajek_arcs = pajek_arcs + make_arc_in_pajek(author_dict[author]['node_id'], i, num)\n",
        "  i += 1\n",
        "\n",
        "print(pajek_vertices)\n",
        "print(pajek_arcs)"
      ],
      "metadata": {
        "id": "wNKZClhxzUCM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "RedditNotebookJan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}